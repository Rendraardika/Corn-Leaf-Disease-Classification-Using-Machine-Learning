{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f0c77d",
   "metadata": {},
   "source": [
    "\n",
    "# Corn Leaf Disease Detection with Enhanced KNN (EKNN)\n",
    "\n",
    "Notebook ini mengimplementasikan tahapan utama dari jurnal:\n",
    "\n",
    "> **\"Corn leaf image classification based on machine learning techniques for accurate leaf disease detection\" (IJECE, 2022)**\n",
    "\n",
    "Pipeline:\n",
    "\n",
    "1. Pre-processing (normalisasi, grayscale, reduksi noise)\n",
    "2. Segmentasi dengan **Otsu Thresholding**\n",
    "3. Ekstraksi fitur (Fine, Coarse, DOR)\n",
    "4. Klasifikasi dengan Enhanced K-Nearest Neighbour (EKNN)\n",
    "5. Evaluasi: Confusion Matrix, Classification Report, ROC multi-kelas\n",
    "6. Visualisasi: Before–After preprocessing & segmentasi per kelas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e90ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import cycle\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6, 4)\n",
    "plt.rcParams['figure.dpi'] = 120\n",
    "\n",
    "print(\"Libraries loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb45a57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Setelah unzip\n",
    "!unzip /content/archive.zip -d /content/\n",
    "\n",
    "# Pindahkan folder validation ke lokasi dataset final\n",
    "!mv \"/content/data jagung/validation\" \"/content/dataset\"\n",
    "\n",
    "# Set direktori dataset\n",
    "BASE_DIR = \"/content/dataset\"\n",
    "\n",
    "CLASS_MAP = {\n",
    "    \"daun sehat\": \"HL\",\n",
    "    \"bercak daun\": \"LSG\",\n",
    "    \"hawar daun\": \"NLB\",\n",
    "    \"karat daun\": \"RS\"\n",
    "}\n",
    "\n",
    "print(\"Base directory :\", BASE_DIR)\n",
    "print(\"Kelas yang diharapkan:\", CLASS_MAP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93c55f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Setelah unzip\n",
    "!unzip /content/archive.zip -d /content/\n",
    "\n",
    "# Pindahkan folder validation ke lokasi dataset final\n",
    "!mv \"/content/data jagung/validation\" \"/content/dataset\"\n",
    "\n",
    "# Set direktori dataset\n",
    "BASE_DIR = \"/content/dataset\"\n",
    "\n",
    "CLASS_MAP = {\n",
    "    \"daun sehat\": \"HL\",\n",
    "    \"bercak daun\": \"LSG\",\n",
    "    \"hawar daun\": \"NLB\",\n",
    "    \"karat daun\": \"RS\"\n",
    "}\n",
    "\n",
    "print(\"Base directory :\", BASE_DIR)\n",
    "print(\"Kelas yang diharapkan:\", CLASS_MAP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127bc4d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================================================\n",
    "# PRE-PROCESSING & SEGMENTASI\n",
    "# ===================================================================================\n",
    "\n",
    "def preprocess_image(img, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Preprocessing citra daun jagung.\n",
    "\n",
    "    Tahapan:\n",
    "    1. Resize ke ukuran target (default 256x256, sejalan dengan PlantVillage).\n",
    "    2. BGR (OpenCV) -> RGB.\n",
    "    3. Normalisasi piksel ke [0, 1].\n",
    "    4. Konversi ke grayscale.\n",
    "    \"\"\"\n",
    "    img_resized = cv2.resize(img, target_size)\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    img_rgb_norm = img_rgb.astype(\"float32\") / 255.0\n",
    "    gray = cv2.cvtColor((img_rgb_norm * 255).astype(\"uint8\"), cv2.COLOR_RGB2GRAY)\n",
    "    return img_rgb_norm, gray\n",
    "\n",
    "\n",
    "def segment_otsu(gray):\n",
    "    \"\"\"\n",
    "    Segmentasi Otsu berbasis intensitas.\n",
    "\n",
    "    1. Gaussian blur untuk mereduksi noise.\n",
    "    2. Thresholding Otsu -> citra biner.\n",
    "    \"\"\"\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, otsu_binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return otsu_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430eb78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================================================\n",
    "# VISUALISASI: BEFORE–AFTER PREPROCESSING & OTSU SEGMENTATION\n",
    "# ===================================================================================\n",
    "\n",
    "import random\n",
    "\n",
    "def show_before_after(path):\n",
    "    \"\"\"\n",
    "    Menampilkan:\n",
    "    - Citra asli (RGB)\n",
    "    - Citra grayscale\n",
    "    - Hasil segmentasi Otsu\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        print(\"Gagal membaca citra:\", path)\n",
    "        return\n",
    "\n",
    "    rgb_norm, gray = preprocess_image(img)\n",
    "    otsu_bin = segment_otsu(gray)\n",
    "\n",
    "    plt.figure(figsize=(9, 3))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(gray, cmap=\"gray\")\n",
    "    plt.title(\"Grayscale\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(otsu_bin, cmap=\"gray\")\n",
    "    plt.title(\"Otsu Segmentation\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(os.path.basename(path))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Contoh visualisasi before-after per kelas:\\n\")\n",
    "for folder_name in CLASS_MAP.keys():\n",
    "    folder_path = os.path.join(BASE_DIR, folder_name)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    files = [f for f in os.listdir(folder_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    if not files:\n",
    "        continue\n",
    "    sample_path = os.path.join(folder_path, random.choice(files))\n",
    "    print(f\"Kelas: {folder_name}, contoh file: {sample_path}\")\n",
    "    show_before_after(sample_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed67e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================================================\n",
    "# EKSTRAKSI FITUR: FINE, COARSE, DOR\n",
    "# ===================================================================================\n",
    "\n",
    "def extract_fine_features(gray, radius=1, neighbors=8, step=2):\n",
    "    \"\"\"\n",
    "    Fine Features berbasis pola tekstur lokal (mirip LBP rotation-invariant).\n",
    "\n",
    "    - Untuk setiap piksel pusat (sampling step):\n",
    "      * Bandingkan intensitas tetangga di lingkaran radius tertentu.\n",
    "      * Bentuk kode biner (>= center -> 1, < center -> 0).\n",
    "      * Jadikan rotation-invariant dengan mencari rotasi minimum.\n",
    "    - Bungkus dalam bentuk histogram sehingga dimensi tetap.\n",
    "    \"\"\"\n",
    "    h, w = gray.shape\n",
    "    codes = []\n",
    "\n",
    "    for y in range(radius, h - radius, step):\n",
    "        for x in range(radius, w - radius, step):\n",
    "            center = gray[y, x]\n",
    "            binary = []\n",
    "            for n in range(neighbors):\n",
    "                theta = 2.0 * np.pi * n / neighbors\n",
    "                yy = int(round(y + radius * np.sin(theta)))\n",
    "                xx = int(round(x + radius * np.cos(theta)))\n",
    "                binary.append(1 if gray[yy, xx] >= center else 0)\n",
    "\n",
    "            rotations = [\n",
    "                int(\"\".join(map(str, binary[i:] + binary[:i])), 2)\n",
    "                for i in range(neighbors)\n",
    "            ]\n",
    "            ri_code = min(rotations)\n",
    "            codes.append(ri_code)\n",
    "\n",
    "    hist, _ = np.histogram(codes, bins=256, range=(0, 256))\n",
    "    hist = hist.astype(\"float32\")\n",
    "    if hist.sum() > 0:\n",
    "        hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def extract_coarse_features(gray, num_bins=32):\n",
    "    \"\"\"\n",
    "    Coarse Features berdasarkan magnitude gradien (struktur global).\n",
    "\n",
    "    - Hitung gradien x dan y (Sobel).\n",
    "    - Hitung magnitude gradien.\n",
    "    - Buat histogram magnitude sebagai fitur.\n",
    "    \"\"\"\n",
    "    sobelx = cv2.Sobel(gray.astype(\"float32\"), cv2.CV_32F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(gray.astype(\"float32\"), cv2.CV_32F, 0, 1, ksize=3)\n",
    "    magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    hist, _ = np.histogram(magnitude, bins=num_bins, range=(0, magnitude.max() + 1e-6))\n",
    "    hist = hist.astype(\"float32\")\n",
    "    if hist.sum() > 0:\n",
    "        hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def extract_dor_features(gray, window_size=5):\n",
    "    \"\"\"\n",
    "    Confined Intensity Directional Order Relation (DOR) sederhana.\n",
    "\n",
    "    - Ambil jendela lokal (window_size x window_size) di sekitar tiap piksel.\n",
    "    - Hitung selisih absolut intensitas tetangga terhadap pusat.\n",
    "    - Tetangga dengan selisih terbesar => dominant direction.\n",
    "    - Histogram frekuensi dominant direction menjadi fitur.\n",
    "    \"\"\"\n",
    "    assert window_size % 2 == 1, \"window_size harus ganjil\"\n",
    "\n",
    "    pad = window_size // 2\n",
    "    padded = np.pad(gray.astype(\"float32\"), pad, mode=\"reflect\")\n",
    "    h, w = gray.shape\n",
    "    dom_idx = []\n",
    "\n",
    "    for y in range(pad, h + pad):\n",
    "        for x in range(pad, w + pad):\n",
    "            region = padded[y-pad:y+pad+1, x-pad:x+pad+1]\n",
    "            center = padded[y, x]\n",
    "            diffs = np.abs(region - center).flatten()\n",
    "            idx = int(np.argmax(diffs))\n",
    "            dom_idx.append(idx)\n",
    "\n",
    "    num_pos = window_size * window_size\n",
    "    hist, _ = np.histogram(dom_idx, bins=num_pos, range=(0, num_pos))\n",
    "    hist = hist.astype(\"float32\")\n",
    "    if hist.sum() > 0:\n",
    "        hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def extract_all_features(gray):\n",
    "    \"\"\"\n",
    "    Wrapper untuk menggabungkan:\n",
    "    - Fine features\n",
    "    - Coarse features\n",
    "    - DOR features\n",
    "\n",
    "    Hasil akhirnya adalah satu vektor fitur berdimensi tetap.\n",
    "    \"\"\"\n",
    "    fine = extract_fine_features(gray)\n",
    "    coarse = extract_coarse_features(gray)\n",
    "    dor = extract_dor_features(gray)\n",
    "    feat_vec = np.concatenate([fine, coarse, dor]).astype(\"float32\")\n",
    "    return feat_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4af72d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================================================\n",
    "# LOAD DATASET & GENERATE FITUR\n",
    "# ===================================================================================\n",
    "\n",
    "def load_dataset(base_dir, class_map, max_images_per_class=None):\n",
    "    \"\"\"\n",
    "    Memuat citra daun jagung dari struktur folder dan menghasilkan fitur.\n",
    "\n",
    "    - Loop setiap folder kelas sesuai class_map.\n",
    "    - Preprocessing (resize, RGB, normalisasi, grayscale).\n",
    "    - Segmentasi Otsu (untuk visualisasi / konsistensi pipeline).\n",
    "    - Ekstraksi fitur (fine + coarse + DOR).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_dir : str\n",
    "        Folder utama dataset.\n",
    "    class_map : dict\n",
    "        Mapping nama folder -> label (string).\n",
    "    max_images_per_class : int or None\n",
    "        Batas jumlah citra per kelas (opsional).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray\n",
    "        Matriks fitur (num_samples x num_features).\n",
    "    y : np.ndarray\n",
    "        Label kelas untuk setiap sampel.\n",
    "    paths : list of str\n",
    "        Path citra yang digunakan.\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    paths = []\n",
    "\n",
    "    for folder_name, label in class_map.items():\n",
    "        folder_path = os.path.join(base_dir, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"[PERINGATAN] Folder tidak ditemukan: {folder_path}\")\n",
    "            continue\n",
    "\n",
    "        files = [f for f in os.listdir(folder_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "        files = sorted(files)\n",
    "        if max_images_per_class is not None:\n",
    "            files = files[:max_images_per_class]\n",
    "\n",
    "        print(f\"Memproses kelas '{folder_name}' ({label}), jumlah citra: {len(files)}\")\n",
    "\n",
    "        for fname in files:\n",
    "            fpath = os.path.join(folder_path, fname)\n",
    "            img = cv2.imread(fpath)\n",
    "            if img is None:\n",
    "                print(\"  [SKIP] Gagal baca citra:\", fpath)\n",
    "                continue\n",
    "\n",
    "            rgb_norm, gray = preprocess_image(img)\n",
    "            _ = segment_otsu(gray)  # tidak digunakan langsung untuk fitur di sini\n",
    "\n",
    "            feat = extract_all_features(gray)\n",
    "            X_list.append(feat)\n",
    "            y_list.append(label)\n",
    "            paths.append(fpath)\n",
    "\n",
    "    X = np.vstack(X_list).astype(\"float32\")\n",
    "    y = np.array(y_list)\n",
    "    print(\"\\nTotal sampel:\", X.shape[0])\n",
    "    print(\"Dimensi fitur:\", X.shape[1])\n",
    "    return X, y, paths\n",
    "\n",
    "\n",
    "# Jalankan loading dataset\n",
    "\n",
    "# --- FIX START ---\n",
    "# Update BASE_DIR to point to the validation folder\n",
    "BASE_DIR = os.path.join(BASE_DIR, \"validation\")\n",
    "\n",
    "# Correct CLASS_MAP to match actual folder names\n",
    "# 'bercak daun' corresponds to 'daun rusak' in the file system\n",
    "CLASS_MAP_FIXED = {\n",
    "    \"daun sehat\": CLASS_MAP[\"daun sehat\"],\n",
    "    \"daun rusak\": CLASS_MAP[\"bercak daun\"], # Corrected folder name\n",
    "    \"hawar daun\": CLASS_MAP[\"hawar daun\"],\n",
    "    \"karat daun\": CLASS_MAP[\"karat daun\"]\n",
    "}\n",
    "\n",
    "X, y, img_paths = load_dataset(BASE_DIR, CLASS_MAP_FIXED, max_images_per_class=None)\n",
    "# --- FIX END ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9cb91",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================================================\n",
    "# TRAINING EKNN\n",
    "# ===================================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test, paths_train, paths_test = train_test_split(\n",
    "    X, y, img_paths, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Ukuran train:\", X_train.shape, \"Ukuran test:\", X_test.shape)\n",
    "\n",
    "# Enhanced KNN: struktur classifier tetap KNN,\n",
    "# tetapi fitur yang dimasukkan sudah \"enhanced\" (fine + coarse + DOR).\n",
    "eknn = KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\")\n",
    "eknn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model EKNN selesai dilatih.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
